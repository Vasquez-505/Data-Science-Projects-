{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasquez-505/Data-Science-Projects-/blob/main/docs/notebooks/Training_and_inference_using_Google_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaRFOIzzhZGD"
      },
      "source": [
        "# Training and inference on your own data using Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SLEAP Instalation\n"
      ],
      "metadata": {
        "id": "DmLUpI7Yz7gM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUfnkxMtLcK3",
        "outputId": "d04b0783-360b-4d39-f111-e32542231fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: sleap 1.5.1 does not provide the extra 'pypi'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m878.8/878.8 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m911.5/911.5 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.4/249.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.8/557.8 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.2/170.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.1/271.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.7/336.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nixio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            " SLEAP version: 1.5.1\n",
            " PyTorch version: 2.8.0+cu126\n",
            " CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]>=1.5.1\"\n",
        "\n",
        "# --- Sanity checks ---\n",
        "import sleap, torch\n",
        "print(\" SLEAP version:\", sleap.__version__)\n",
        "print(\" PyTorch version:\", torch.__version__)\n",
        "print(\" CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]==1.5.1\" sleap-io==0.5.5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guty-iAksNRx",
        "outputId": "4f5529a2-fbc8-4138-aad9-a853c5ab9c7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: sleap 1.5.1 does not provide the extra 'pypi'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -qqq \"sleap-nn[torch-cuda-128]\""
      ],
      "metadata": {
        "id": "LKJP-LabvvUQ",
        "outputId": "37742ee0-1beb-44f8-cb0e-456de1e2c527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: sleap-nn 0.0.2 does not provide the extra 'torch-cuda-128'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check\n",
        "import sleap, sleap_io\n",
        "print(\"SLEAP:\", sleap.__version__)\n",
        "print(\"SLEAP-IO:\", sleap_io.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUyk67xxs1C5",
        "outputId": "81517ce4-801d-46d2-c107-8a5ae6f46e12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLEAP: 1.5.1\n",
            "SLEAP-IO: 0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwpEwrxYdLMR"
      },
      "source": [
        "### Create and export the training job package\n",
        "A self-contained **training job package** contains a .slp file with labeled data and images which will be used for training, as well as .json training configuration file(s).\n",
        "\n",
        "A training job package can be exported in the SLEAP GUI fron the \"Run Training..\" dialog under the \"Predict\" menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApaDWxW4dLMS"
      },
      "source": [
        "### Upload training job package to Google Drive\n",
        "To be consistent with the examples in this notebook, name the SLEAP project `colab` and create a directory called `sleap` in the root of your Google Drive. Then upload the exported training job package `colab.slp.training_job.zip` into `sleap` directory.\n",
        "\n",
        "If you place your training pckage somewhere else, or name it differently, adjust the paths/filenames/parameters below accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBWjF4jpMG2N",
        "outputId": "a02ca0c7-13d3-478c-f2c5-4f8f247d4293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umui-gI2rBz",
        "outputId": "401a6bf6-d8d6-45b0-b5f8-4a8ec84def22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab.pkg.slp\t\t    jobs.yaml\t\t  train-script.sh\n",
            "colab.slp.training_job.zip  models\n",
            "inference-script.sh\t    single_instance.yaml\n"
          ]
        }
      ],
      "source": [
        "## ----- THIS PART IS NOT NEEDED ANYMORE ----- ##\n",
        "\n",
        "# This step was to import the training package initially. Instead of Importing the training package everytime we want to train a new model,\n",
        "# just modify the desired parameters in the following MASTER SCRIPT)\n",
        "\n",
        "# If you haven´t imported a single training package to the drive run this cell\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/sleap\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MASTER Config Trainer Update"
      ],
      "metadata": {
        "id": "qJyxK0Ts1s_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === MASTER CONFIG UPDATER (no inference) ===\n",
        "# Edits: single_instance.yaml, jobs.yaml, train-script.sh\n",
        "# Matches your schema exactly.\n",
        "\n",
        "import os, yaml, datetime, pathlib\n",
        "\n",
        "# ------------------------------\n",
        "# PICK YOUR RUN / MODEL NAME HERE\n",
        "# ------------------------------\n",
        "RUN_NAME = \"drosophila_unet_1_\" + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "LABELS_PATH = \"colab.pkg.slp\"          # or \"colab copy.pkg.slp\"\n",
        "# Define where checkpoints should be saved\n",
        "EXPLICIT_CKPT_DIR = f\"models/{RUN_NAME}\"\n",
        "\n",
        "# Prevent double-nesting of model directories\n",
        "# (SLEAP already creates {ckpt_dir}/{run_name}/... internally)\n",
        "if RUN_NAME in EXPLICIT_CKPT_DIR:\n",
        "    CKPT_DIR = \"models\"\n",
        "else:\n",
        "    CKPT_DIR = EXPLICIT_CKPT_DIR\n",
        "\n",
        "\n",
        "SINGLE_INSTANCE_YAML = \"single_instance.yaml\"\n",
        "JOBS_YAML = \"jobs.yaml\"\n",
        "TRAIN_SH = \"train-script.sh\"\n",
        "\n",
        "# ------------------------------\n",
        "# FULL PARAMETER BLOCKS (edit anything)\n",
        "# ------------------------------\n",
        "\n",
        "DATA_CONFIG = {\n",
        "    \"train_labels_path\": [LABELS_PATH],\n",
        "    \"val_labels_path\": None,\n",
        "    \"validation_fraction\": 0.1,\n",
        "    \"test_file_path\": None,\n",
        "    \"provider\": \"LabelsReader\",\n",
        "    \"user_instances_only\": True,\n",
        "    \"data_pipeline_fw\": \"torch_dataset\",\n",
        "    \"cache_img_path\": None,\n",
        "    \"use_existing_imgs\": False,\n",
        "    \"delete_cache_imgs_after_training\": True,\n",
        "    \"preprocessing\": {\n",
        "        \"ensure_rgb\": True,            # set True if your images are RGB\n",
        "        \"ensure_grayscale\": False,      # set True if you force grayscale\n",
        "        \"max_height\": None,             # e.g., 182\n",
        "        \"max_width\": None,              # e.g., 682\n",
        "        \"scale\": 1.0,                   # <- critical input scaling\n",
        "        \"crop_size\": None,              # or [H, W]\n",
        "        \"min_crop_size\": 100,\n",
        "    },\n",
        "    \"use_augmentations_train\": False,\n",
        "    \"augmentation_config\": {\n",
        "        \"intensity\": {\n",
        "            \"uniform_noise_min\": 0.0,\n",
        "            \"uniform_noise_max\": 1.0,\n",
        "            \"uniform_noise_p\": 0.0,\n",
        "            \"gaussian_noise_mean\": 5.0,\n",
        "            \"gaussian_noise_std\": 0.0,\n",
        "            \"gaussian_noise_p\": 0.0,\n",
        "            \"contrast_min\": 0.5,\n",
        "            \"contrast_max\": 1.75,\n",
        "            \"contrast_p\": 0.0,\n",
        "            \"brightness_min\": 0.0,\n",
        "            \"brightness_max\": 2.0,\n",
        "            \"brightness_p\": 0.0,\n",
        "        },\n",
        "        \"geometric\": {\n",
        "            \"rotation_min\": -15.0,\n",
        "            \"rotation_max\": 15.0,\n",
        "            \"scale_min\": 0.9,\n",
        "            \"scale_max\": 1.1,\n",
        "            \"translate_width\": 0.0,\n",
        "            \"translate_height\": 0.0,\n",
        "            \"affine_p\": 1.0,\n",
        "            \"erase_scale_min\": 0.0001,\n",
        "            \"erase_scale_max\": 0.01,\n",
        "            \"erase_ratio_min\": 1.0,\n",
        "            \"erase_ratio_max\": 1.0,\n",
        "            \"erase_p\": 0.0,\n",
        "            \"mixup_lambda_min\": 0.01,\n",
        "            \"mixup_lambda_max\": 0.05,\n",
        "            \"mixup_p\": 0.0,\n",
        "        },\n",
        "    },\n",
        "    \"skeletons\": None,\n",
        "}\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    \"init_weights\": \"default\",\n",
        "    \"pretrained_backbone_weights\": None,\n",
        "    \"pretrained_head_weights\": None,\n",
        "    \"backbone_config\": {\n",
        "        \"unet\": {\n",
        "            \"in_channels\": 1,      # 1 for grayscale, 3 for RGB\n",
        "            \"kernel_size\": 3,\n",
        "            \"filters\": 32,\n",
        "            \"filters_rate\": 1.5,\n",
        "            \"max_stride\": 32,\n",
        "            \"stem_stride\": None,\n",
        "            \"middle_block\": True,\n",
        "            \"up_interpolate\": True,\n",
        "            \"stacks\": 1,\n",
        "            \"convs_per_block\": 2,\n",
        "            \"output_stride\": 4,\n",
        "        },\n",
        "        \"convnext\": None,\n",
        "        \"swint\": None,\n",
        "    },\n",
        "    \"head_configs\": {\n",
        "        \"single_instance\": {\n",
        "            \"confmaps\": {\n",
        "                \"part_names\": None,   # auto from labels if None\n",
        "                \"sigma\": 2.5,\n",
        "                \"output_stride\": 4,\n",
        "            }\n",
        "        },\n",
        "        \"centroid\": None,\n",
        "        \"centered_instance\": None,\n",
        "        \"bottomup\": None,\n",
        "        \"multi_class_bottomup\": None,\n",
        "        \"multi_class_topdown\": None,\n",
        "    },\n",
        "    \"total_params\": None,\n",
        "}\n",
        "\n",
        "TRAINER_CONFIG = {\n",
        "    \"train_data_loader\": {\"batch_size\": 6, \"shuffle\": False, \"num_workers\": 0},\n",
        "    \"val_data_loader\": {\"batch_size\": 6, \"shuffle\": False, \"num_workers\": 0},\n",
        "    \"model_ckpt\": {\"save_top_k\": 1, \"save_last\": False},\n",
        "    \"trainer_devices\": None,              # 'auto' or explicit list\n",
        "    \"trainer_device_indices\": None,\n",
        "    \"trainer_accelerator\": \"auto\",\n",
        "    \"profiler\": None,\n",
        "    \"trainer_strategy\": \"auto\",\n",
        "    \"enable_progress_bar\": True,\n",
        "    \"min_train_steps_per_epoch\": 200,\n",
        "    \"train_steps_per_epoch\": None,\n",
        "    \"visualize_preds_during_training\": True,\n",
        "    \"keep_viz\": False,\n",
        "    \"max_epochs\": 200,\n",
        "    \"seed\": None,\n",
        "    \"use_wandb\": False,\n",
        "    \"save_ckpt\": True,\n",
        "    \"ckpt_dir\": CKPT_DIR,\n",
        "    \"run_name\": RUN_NAME,\n",
        "    \"resume_ckpt_path\": None,\n",
        "    \"wandb\": {\n",
        "        \"entity\": \"\",\n",
        "        \"project\": \"\",\n",
        "        \"name\": \"\",\n",
        "        \"save_viz_imgs_wandb\": False,\n",
        "        \"api_key\": \"\",\n",
        "        \"wandb_mode\": None,\n",
        "        \"prv_runid\": \"\",\n",
        "        \"group\": \"\",\n",
        "        \"current_run_id\": None,\n",
        "    },\n",
        "    \"optimizer_name\": \"Adam\",\n",
        "    \"optimizer\": {\"lr\": 1e-4, \"amsgrad\": False},\n",
        "    \"lr_scheduler\": None,\n",
        "    \"early_stopping\": {\n",
        "        \"min_delta\": 1e-8,\n",
        "        \"patience\": 30,\n",
        "        \"stop_training_on_plateau\": True,\n",
        "    },\n",
        "    \"online_hard_keypoint_mining\": {\n",
        "        \"online_mining\": False,\n",
        "        \"hard_to_easy_ratio\": 2.0,\n",
        "        \"min_hard_keypoints\": 2,\n",
        "        \"max_hard_keypoints\": None,\n",
        "        \"loss_scale\": 5.0,\n",
        "    },\n",
        "    \"zmq\": {\n",
        "        \"controller_port\": 9000,\n",
        "        \"controller_polling_timeout\": 10,\n",
        "        \"publish_port\": 9001,\n",
        "    },\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# Helpers\n",
        "# ------------------------------\n",
        "def _ensure_keys(d, template):\n",
        "    \"\"\"Recursively ensure keys from template exist in dict d.\"\"\"\n",
        "    if d is None:\n",
        "        return template\n",
        "    for k, v in template.items():\n",
        "        if k not in d or d[k] is None:\n",
        "            d[k] = v\n",
        "        else:\n",
        "            if isinstance(v, dict):\n",
        "                d[k] = _ensure_keys(d.get(k, {}), v)\n",
        "    return d\n",
        "\n",
        "def _safe_update(d, updates):\n",
        "    \"\"\"Recursively update d with updates, preserving other keys.\"\"\"\n",
        "    for k, v in updates.items():\n",
        "        if isinstance(v, dict):\n",
        "            d[k] = _safe_update(d.get(k, {}) if isinstance(d.get(k), dict) else {}, v)\n",
        "        else:\n",
        "            d[k] = v\n",
        "    return d\n",
        "\n",
        "def _load_yaml(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "def _save_yaml(path, data):\n",
        "    with open(path, \"w\") as f:\n",
        "        yaml.safe_dump(data, f, sort_keys=False)\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Update single_instance.yaml\n",
        "# ------------------------------\n",
        "si = _load_yaml(SINGLE_INSTANCE_YAML)\n",
        "\n",
        "# Ensure structure exists exactly as your schema\n",
        "si = _ensure_keys(si, {\n",
        "    \"data_config\": {},\n",
        "    \"model_config\": {},\n",
        "    \"trainer_config\": {},\n",
        "    \"name\": \"\",\n",
        "    \"description\": \"\",\n",
        "    \"sleap_nn_version\": si.get(\"sleap_nn_version\", \"0.0.2\"),\n",
        "    \"filename\": \"\",\n",
        "})\n",
        "\n",
        "# Merge updates\n",
        "si[\"data_config\"]      = _safe_update(si[\"data_config\"], DATA_CONFIG)\n",
        "si[\"model_config\"]     = _safe_update(si[\"model_config\"], MODEL_CONFIG)\n",
        "si[\"trainer_config\"]   = _safe_update(si[\"trainer_config\"], TRAINER_CONFIG)\n",
        "si[\"trainer_config\"][\"run_name\"] = RUN_NAME\n",
        "si[\"trainer_config\"][\"ckpt_dir\"] = CKPT_DIR\n",
        "\n",
        "# Save\n",
        "# Ensure model folder exists for cleanliness\n",
        "pathlib.Path(CKPT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "_save_yaml = _save_yaml  # avoid accidental shadowing\n",
        "_save_yaml(SINGLE_INSTANCE_YAML, si)\n",
        "print(f\" Updated {SINGLE_INSTANCE_YAML} with run_name={RUN_NAME}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Update jobs.yaml (best effort; keeps structure)\n",
        "# ------------------------------\n",
        "if os.path.exists(JOBS_YAML):\n",
        "    jobs = _load_yaml(JOBS_YAML)\n",
        "\n",
        "    # Try common fields used by Colab templates; only update if present\n",
        "    # We keep your structure intact.\n",
        "    def set_if_exists(root, keys, value):\n",
        "        cur = root\n",
        "        for k in keys[:-1]:\n",
        "            if not isinstance(cur, dict) or k not in cur:\n",
        "                return\n",
        "            cur = cur[k]\n",
        "        if isinstance(cur, dict) and keys[-1] in cur:\n",
        "            cur[keys[-1]] = value\n",
        "\n",
        "    # Common spots we might find these\n",
        "    set_if_exists(jobs, [\"training_job\", \"trainer_config\", \"run_name\"], RUN_NAME)\n",
        "    set_if_exists(jobs, [\"training_job\", \"trainer_config\", \"ckpt_dir\"], CKPT_DIR)\n",
        "    set_if_exists(jobs, [\"training_job\", \"data_config\", \"train_labels_path\"], [LABELS_PATH])\n",
        "    set_if_exists(jobs, [\"training_job\", \"config_path\"], SINGLE_INSTANCE_YAML)\n",
        "\n",
        "    _save_yaml(JOBS_YAML, jobs)\n",
        "    print(f\" Updated {JOBS_YAML} (run_name, ckpt_dir, labels if present)\")\n",
        "else:\n",
        "    print(f\" {JOBS_YAML} not found — skipped (that’s fine).\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Update train-script.sh\n",
        "# ------------------------------\n",
        "train_script = f\"\"\"#!/bin/bash\n",
        "# Auto-generated: {RUN_NAME}\n",
        "echo \"Starting SLEAP training: {RUN_NAME}\"\n",
        "sleap-train {SINGLE_INSTANCE_YAML} {LABELS_PATH} --first-gpu\n",
        "\"\"\"\n",
        "with open(TRAIN_SH, \"w\") as f:\n",
        "    f.write(train_script)\n",
        "os.chmod(TRAIN_SH, 0o755)\n",
        "print(f\" Updated {TRAIN_SH}\")\n",
        "\n",
        "print(f\"\\n Ready. Model/run name: {RUN_NAME}\\nCheckpoints: {CKPT_DIR}\\nLabels: {LABELS_PATH}\")\n"
      ],
      "metadata": {
        "id": "LcOHBV0v4x-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d33409-d2af-457e-d16d-291fcd4baa04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Updated single_instance.yaml with run_name=drosophila_unet_1_251019_094425\n",
            "✅ Updated jobs.yaml (run_name, ckpt_dir, labels if present)\n",
            " Updated train-script.sh\n",
            "\n",
            " Ready. Model/run name: drosophila_unet_1_251019_094425\n",
            "Checkpoints: models/drosophila_unet_1_251019_094425\n",
            "Labels: colab.pkg.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "Let's train a model with the training profile (.json file) and the project data (.slp file) you have exported from SLEAP.\n",
        "\n",
        "\n",
        "### Note on training profiles\n",
        "Depending on the pipeline you chose in the training dialog, the config filename(s) will be:\n",
        "\n",
        "- for a **bottom-up** pipeline approach: `multi_instance.json` (this is the pipeline we assume here),\n",
        "\n",
        "- for a **top-down** pipeline, you'll have a different profile for each of the models: `centroid.json` and `centered_instance.json`,\n",
        "\n",
        "- for a **single animal** pipeline: `single_instance.json`.\n",
        "\n",
        "\n",
        "### Note on training process\n",
        "When you start training, you'll first see the training parameters and then the training and validation loss for each training epoch.\n",
        "\n",
        "As soon as you're satisfied with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference.\n",
        "\n",
        "If you don't stop training, it will run for 200 epochs or until validation loss fails to improve for some number of epochs (controlled by the early_stopping fields in the training profile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QKf6qzMqNBUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37de25e4-a93c-4604-c7f0-8af0afddd5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:sleap.legacy_cli_adaptors:Started training at: 2025-10-19 10:00:11.485656\n",
            "2025-10-19 10:00:11 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:216 | Creating train-val split...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:261 | # Train Labeled frames: 407\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:262 | # Val Labeled frames: 45\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:setup_config:512 | Setting up config...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:_verify_model_input_channels:417 | Updating backbone in_channels to 3 based on the input image channels.\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:train:849 | Setting up for training...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:_setup_model_ckpt_dir:575 | Setting up model ckpt dir: `models/drosophila_unet_1_251019_094425/drosophila_unet_1_251019_094425`...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:train:864 | Setting up visualization train and val datasets...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:train:868 | Setting up Trainer...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:_setup_loggers_callbacks:647 | Setting up callbacks and loggers...\n",
            "2025-10-19 10:00:12 | INFO | sleap_nn.training.model_trainer:train:897 | Trainer devices: auto\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:950 | Training on 1 device(s)\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:951 | Training on cuda:0 accelerator\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:955 | Setting up lightning module for single_instance model...\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:959 | Backbone model: UNet(\n",
            "  (encoders): ModuleList(\n",
            "    (0): Encoder(\n",
            "      (encoder_stack): ModuleList(\n",
            "        (0): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc0_conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc0_act0_relu): ReLU()\n",
            "            (stack0_enc0_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc0_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc1_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc1_conv0): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc1_act0_relu): ReLU()\n",
            "            (stack0_enc1_conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc1_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (2): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc2_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc2_conv0): Conv2d(48, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc2_act0_relu): ReLU()\n",
            "            (stack0_enc2_conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc2_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (3): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc3_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc3_conv0): Conv2d(72, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc3_act0_relu): ReLU()\n",
            "            (stack0_enc3_conv1): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc3_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (4): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc4_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc4_conv0): Conv2d(108, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc4_act0_relu): ReLU()\n",
            "            (stack0_enc4_conv1): Conv2d(162, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc4_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (stack0_enc5_last_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoders): ModuleList(\n",
            "    (0): Decoder(\n",
            "      (decoder_stack): ModuleList(\n",
            "        (0): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec0_s32_to_s16_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec0_s32_to_s16_refine_conv0): Conv2d(405, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec0_s32_to_s16_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec0_s32_to_s16_refine_conv1): Conv2d(162, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec0_s32_to_s16_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec1_s16_to_s8_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec1_s16_to_s8_refine_conv0): Conv2d(270, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec1_s16_to_s8_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec1_s16_to_s8_refine_conv1): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec1_s16_to_s8_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (2): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec2_s8_to_s4_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec2_s8_to_s4_refine_conv0): Conv2d(180, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec2_s8_to_s4_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec2_s8_to_s4_refine_conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec2_s8_to_s4_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (middle_blocks): ModuleList(\n",
            "    (0): SimpleConvBlock(\n",
            "      (blocks): Sequential(\n",
            "        (stack0_enc6_middle_expand_conv0): Conv2d(162, 243, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "        (stack0_enc6_middle_expand_act0_relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): SimpleConvBlock(\n",
            "      (blocks): Sequential(\n",
            "        (stack0_enc7_middle_contract_conv0): Conv2d(243, 243, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "        (stack0_enc7_middle_contract_act0_relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:960 | Head model: ModuleList(\n",
            "  (0): Sequential(\n",
            "    (SingleInstanceConfmapsHead): Sequential(\n",
            "      (0): Conv2d(72, 9, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "      (1): Identity()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:962 | Total model parameters: 2936824\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:967 | Input image shape: torch.Size([1, 3, 192, 704])\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:1021 | Finished trainer set up. [0.5s]\n",
            "2025-10-19 10:00:13 | INFO | sleap_nn.training.model_trainer:train:1024 | Starting training loop...\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /content/drive/MyDrive/sleap/models/drosophila_unet_1_251019_094425/drosophila_unet_1_251019_094425 exists and is not empty.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name                      | Type                         | Params | Mode \n",
            "-----------------------------------------------------------------------------------\n",
            "0 | model                     | Model                        | 2.9 M  | train\n",
            "1 | single_instance_inf_layer | SingleInstanceInferenceModel | 0      | train\n",
            "-----------------------------------------------------------------------------------\n",
            "2.9 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.9 M     Total params\n",
            "11.747    Total estimated model params size (MB)\n",
            "80        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name                      | Type                         | Params | Mode \n",
            "-----------------------------------------------------------------------------------\n",
            "0 | model                     | Model                        | 2.9 M  | train\n",
            "1 | single_instance_inf_layer | SingleInstanceInferenceModel | 0      | train\n",
            "-----------------------------------------------------------------------------------\n",
            "2.9 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.9 M     Total params\n",
            "11.747    Total estimated model params size (MB)\n",
            "80        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('learning_rate', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('val_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Sanity Checking DataLoader 0: 100% 2/2 [00:00<00:00,  2.05it/s]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('val_time', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 0:   0% 0/200 [00:00<?, ?it/s]       /usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('head1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('thorax1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('abdomen1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('forelegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('forelegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('midlegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('midlegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('hindlegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('hindlegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 0: 100% 200/200 [00:39<00:00,  5.05it/s, head1_step=0.000423, thorax1_step=0.000423, abdomen1_step=0.000334, forelegR1_step=0.000931, forelegL1_step=0.00106, midlegR1_step=0.00124, midlegL1_step=0.000502, hindlegR1_step=0.000427, hindlegL1_step=0.00146, train_loss_step=0.000755]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.87it/s]\u001b[A\n",
            "Epoch 0: 100% 200/200 [00:41<00:00,  4.82it/s, head1_step=0.000423, thorax1_step=0.000423, abdomen1_step=0.000334, forelegR1_step=0.000931, forelegL1_step=0.00106, midlegR1_step=0.00124, midlegL1_step=0.000502, hindlegR1_step=0.000427, hindlegL1_step=0.00146, train_loss_step=0.000755, learning_rate_step=0.0001, val_loss_step=0.000731, learning_rate_epoch=0.0001, val_loss_epoch=0.000707, head1_epoch=0.00181, thorax1_epoch=0.00155, abdomen1_epoch=0.00192, forelegR1_epoch=0.00126, forelegL1_epoch=0.00144, midlegR1_epoch=0.00213, midlegL1_epoch=0.00138, hindlegR1_epoch=0.00114, hindlegL1_epoch=0.00107, train_loss_epoch=0.00152]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('train_time', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 1: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=0.000227, thorax1_step=0.000132, abdomen1_step=0.000186, forelegR1_step=0.000186, forelegL1_step=0.000387, midlegR1_step=0.000307, midlegL1_step=0.000333, hindlegR1_step=0.000509, hindlegL1_step=0.000497, train_loss_step=0.000307, learning_rate_step=0.0001, val_loss_step=0.000731, learning_rate_epoch=0.0001, val_loss_epoch=0.000707, head1_epoch=0.00181, thorax1_epoch=0.00155, abdomen1_epoch=0.00192, forelegR1_epoch=0.00126, forelegL1_epoch=0.00144, midlegR1_epoch=0.00213, midlegL1_epoch=0.00138, hindlegR1_epoch=0.00114, hindlegL1_epoch=0.00107, train_loss_epoch=0.00152]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.67it/s]\u001b[A\n",
            "Epoch 2: 100% 200/200 [00:39<00:00,  5.01it/s, head1_step=8.66e-5, thorax1_step=8.35e-5, abdomen1_step=7.15e-5, forelegR1_step=0.000103, forelegL1_step=0.000246, midlegR1_step=0.000203, midlegL1_step=3.76e-5, hindlegR1_step=0.000299, hindlegL1_step=9.74e-5, train_loss_step=0.000136, learning_rate_step=0.0001, val_loss_step=0.000433, learning_rate_epoch=0.0001, val_loss_epoch=0.000322, head1_epoch=0.000232, thorax1_epoch=0.000251, abdomen1_epoch=0.000269, forelegR1_epoch=0.000635, forelegL1_epoch=0.000638, midlegR1_epoch=0.000493, midlegL1_epoch=0.000483, hindlegR1_epoch=0.000634, hindlegL1_epoch=0.000545, train_loss_epoch=0.000464]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.12it/s]\u001b[A\n",
            "Epoch 3: 100% 200/200 [00:40<00:00,  4.89it/s, head1_step=8.25e-5, thorax1_step=8.67e-5, abdomen1_step=7.26e-5, forelegR1_step=4.57e-5, forelegL1_step=4.44e-5, midlegR1_step=5.33e-5, midlegL1_step=7.7e-5, hindlegR1_step=0.000149, hindlegL1_step=5.63e-5, train_loss_step=7.42e-5, learning_rate_step=0.0001, val_loss_step=0.000261, learning_rate_epoch=0.0001, val_loss_epoch=0.000199, head1_epoch=0.000156, thorax1_epoch=0.000145, abdomen1_epoch=0.000194, forelegR1_epoch=0.000234, forelegL1_epoch=0.000298, midlegR1_epoch=0.000232, midlegL1_epoch=0.000252, hindlegR1_epoch=0.000317, hindlegL1_epoch=0.000305, train_loss_epoch=0.000237]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.26it/s]\u001b[A\n",
            "Epoch 4: 100% 200/200 [00:40<00:00,  4.93it/s, head1_step=8.06e-5, thorax1_step=5.67e-5, abdomen1_step=7.67e-5, forelegR1_step=2.54e-5, forelegL1_step=0.000159, midlegR1_step=5.49e-5, midlegL1_step=0.00013, hindlegR1_step=0.000412, hindlegL1_step=0.000532, train_loss_step=0.00017, learning_rate_step=0.0001, val_loss_step=0.000228, learning_rate_epoch=0.0001, val_loss_epoch=0.000169, head1_epoch=0.00011, thorax1_epoch=0.000103, abdomen1_epoch=0.000127, forelegR1_epoch=0.000164, forelegL1_epoch=0.000189, midlegR1_epoch=0.000169, midlegL1_epoch=0.00019, hindlegR1_epoch=0.0002, hindlegL1_epoch=0.000219, train_loss_epoch=0.000163] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.16it/s]\u001b[A\n",
            "Epoch 5: 100% 200/200 [00:39<00:00,  5.06it/s, head1_step=6.39e-5, thorax1_step=5.44e-5, abdomen1_step=0.000133, forelegR1_step=4.48e-5, forelegL1_step=2.82e-5, midlegR1_step=0.000103, midlegL1_step=2.76e-5, hindlegR1_step=4.03e-5, hindlegL1_step=2.75e-5, train_loss_step=5.81e-5, learning_rate_step=0.0001, val_loss_step=0.000223, learning_rate_epoch=0.0001, val_loss_epoch=0.000172, head1_epoch=9.41e-5, thorax1_epoch=8.37e-5, abdomen1_epoch=0.000108, forelegR1_epoch=0.000134, forelegL1_epoch=0.000134, midlegR1_epoch=0.000145, midlegL1_epoch=0.000166, hindlegR1_epoch=0.000167, hindlegL1_epoch=0.000174, train_loss_epoch=0.000134]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.27it/s]\u001b[A\n",
            "Epoch 6: 100% 200/200 [00:40<00:00,  4.91it/s, head1_step=0.00012, thorax1_step=9.31e-5, abdomen1_step=0.000207, forelegR1_step=4.94e-5, forelegL1_step=7.67e-5, midlegR1_step=6.02e-5, midlegL1_step=0.000151, hindlegR1_step=0.000146, hindlegL1_step=2.93e-5, train_loss_step=0.000104, learning_rate_step=0.0001, val_loss_step=0.000186, learning_rate_epoch=0.0001, val_loss_epoch=0.000145, head1_epoch=7.89e-5, thorax1_epoch=6.85e-5, abdomen1_epoch=9.5e-5, forelegR1_epoch=0.000109, forelegL1_epoch=0.000104, midlegR1_epoch=0.000125, midlegL1_epoch=0.000149, hindlegR1_epoch=0.000145, hindlegL1_epoch=0.000143, train_loss_epoch=0.000113]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.06it/s]\u001b[A\n",
            "Epoch 7: 100% 200/200 [00:39<00:00,  5.01it/s, head1_step=4.58e-5, thorax1_step=2.3e-5, abdomen1_step=4.22e-5, forelegR1_step=3.2e-5, forelegL1_step=1.5e-5, midlegR1_step=0.000116, midlegL1_step=0.000446, hindlegR1_step=5.15e-5, hindlegL1_step=0.000171, train_loss_step=0.000105, learning_rate_step=0.0001, val_loss_step=0.000285, learning_rate_epoch=0.0001, val_loss_epoch=0.00019, head1_epoch=7.27e-5, thorax1_epoch=6.03e-5, abdomen1_epoch=8.74e-5, forelegR1_epoch=9.08e-5, forelegL1_epoch=8.24e-5, midlegR1_epoch=0.000104, midlegL1_epoch=0.000137, hindlegR1_epoch=0.000122, hindlegL1_epoch=0.000131, train_loss_epoch=9.87e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.84it/s]\u001b[A\n",
            "Epoch 8: 100% 200/200 [00:40<00:00,  4.91it/s, head1_step=2.7e-5, thorax1_step=3.01e-5, abdomen1_step=8.83e-5, forelegR1_step=1.28e-5, forelegL1_step=2.55e-5, midlegR1_step=1.64e-5, midlegL1_step=9.08e-5, hindlegR1_step=1.8e-5, hindlegL1_step=6.6e-5, train_loss_step=4.17e-5, learning_rate_step=0.0001, val_loss_step=9.42e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000115, head1_epoch=6.32e-5, thorax1_epoch=5.68e-5, abdomen1_epoch=7.99e-5, forelegR1_epoch=7.38e-5, forelegL1_epoch=6.95e-5, midlegR1_epoch=8.05e-5, midlegL1_epoch=0.000125, hindlegR1_epoch=0.000102, hindlegL1_epoch=0.00011, train_loss_epoch=8.45e-5]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.96it/s]\u001b[A\n",
            "Epoch 9: 100% 200/200 [00:40<00:00,  4.92it/s, head1_step=5.17e-5, thorax1_step=4.38e-5, abdomen1_step=8.24e-5, forelegR1_step=3.01e-5, forelegL1_step=3.86e-5, midlegR1_step=1.75e-5, midlegL1_step=3.25e-5, hindlegR1_step=5.73e-5, hindlegL1_step=2.24e-5, train_loss_step=4.18e-5, learning_rate_step=0.0001, val_loss_step=8.2e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000112, head1_epoch=5.48e-5, thorax1_epoch=4.81e-5, abdomen1_epoch=6.78e-5, forelegR1_epoch=6.2e-5, forelegL1_epoch=6.01e-5, midlegR1_epoch=5.69e-5, midlegL1_epoch=0.000109, hindlegR1_epoch=8.18e-5, hindlegL1_epoch=8.75e-5, train_loss_epoch=6.98e-5]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.05it/s]\u001b[A\n",
            "Epoch 10: 100% 200/200 [00:40<00:00,  4.95it/s, head1_step=4.87e-5, thorax1_step=2.32e-5, abdomen1_step=9.92e-5, forelegR1_step=1.97e-5, forelegL1_step=0.000124, midlegR1_step=3.39e-5, midlegL1_step=2.07e-5, hindlegR1_step=1.57e-5, hindlegL1_step=1.49e-5, train_loss_step=4.44e-5, learning_rate_step=0.0001, val_loss_step=9.34e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.00011, head1_epoch=5.06e-5, thorax1_epoch=4.18e-5, abdomen1_epoch=6.44e-5, forelegR1_epoch=5.61e-5, forelegL1_epoch=5.34e-5, midlegR1_epoch=4.75e-5, midlegL1_epoch=0.000102, hindlegR1_epoch=7.14e-5, hindlegL1_epoch=7.47e-5, train_loss_epoch=6.25e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.98it/s]\u001b[A\n",
            "Epoch 11: 100% 200/200 [00:40<00:00,  4.93it/s, head1_step=4.13e-5, thorax1_step=2.96e-5, abdomen1_step=0.000101, forelegR1_step=1.88e-5, forelegL1_step=1.97e-5, midlegR1_step=1.85e-5, midlegL1_step=0.000157, hindlegR1_step=3.49e-5, hindlegL1_step=3.24e-5, train_loss_step=5.04e-5, learning_rate_step=0.0001, val_loss_step=8.63e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000107, head1_epoch=5.04e-5, thorax1_epoch=3.95e-5, abdomen1_epoch=6.36e-5, forelegR1_epoch=5.1e-5, forelegL1_epoch=4.83e-5, midlegR1_epoch=4.2e-5, midlegL1_epoch=9.94e-5, hindlegR1_epoch=6.14e-5, hindlegL1_epoch=6.7e-5, train_loss_epoch=5.81e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.01it/s]\u001b[A\n",
            "Epoch 12: 100% 200/200 [00:39<00:00,  5.05it/s, head1_step=2.47e-5, thorax1_step=2.53e-5, abdomen1_step=4.86e-5, forelegR1_step=1.13e-5, forelegL1_step=1.51e-5, midlegR1_step=2.24e-5, midlegL1_step=1.53e-5, hindlegR1_step=1.85e-5, hindlegL1_step=9.23e-6, train_loss_step=2.12e-5, learning_rate_step=0.0001, val_loss_step=9.14e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.00011, head1_epoch=5.28e-5, thorax1_epoch=3.9e-5, abdomen1_epoch=6.41e-5, forelegR1_epoch=4.56e-5, forelegL1_epoch=4.2e-5, midlegR1_epoch=3.61e-5, midlegL1_epoch=8.86e-5, hindlegR1_epoch=5.46e-5, hindlegL1_epoch=6.17e-5, train_loss_epoch=5.38e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.57it/s]\u001b[A\n",
            "Epoch 13: 100% 200/200 [00:41<00:00,  4.81it/s, head1_step=5.11e-5, thorax1_step=3.63e-5, abdomen1_step=5.32e-5, forelegR1_step=3.35e-5, forelegL1_step=1.31e-5, midlegR1_step=1.46e-5, midlegL1_step=4.31e-5, hindlegR1_step=2.49e-5, hindlegL1_step=3.13e-5, train_loss_step=3.35e-5, learning_rate_step=0.0001, val_loss_step=9.13e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000105, head1_epoch=5.15e-5, thorax1_epoch=3.98e-5, abdomen1_epoch=5.58e-5, forelegR1_epoch=4.39e-5, forelegL1_epoch=3.85e-5, midlegR1_epoch=3.36e-5, midlegL1_epoch=8.46e-5, hindlegR1_epoch=5.13e-5, hindlegL1_epoch=5.79e-5, train_loss_epoch=5.08e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.77it/s]\u001b[A\n",
            "Epoch 14: 100% 200/200 [00:40<00:00,  4.99it/s, head1_step=2.92e-5, thorax1_step=3.08e-5, abdomen1_step=3.82e-5, forelegR1_step=0.000395, forelegL1_step=0.000165, midlegR1_step=1.68e-5, midlegL1_step=0.000387, hindlegR1_step=1.68e-5, hindlegL1_step=1.44e-5, train_loss_step=0.000122, learning_rate_step=0.0001, val_loss_step=7.28e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000103, head1_epoch=5.31e-5, thorax1_epoch=3.71e-5, abdomen1_epoch=4.88e-5, forelegR1_epoch=4.19e-5, forelegL1_epoch=3.49e-5, midlegR1_epoch=3.2e-5, midlegL1_epoch=8.03e-5, hindlegR1_epoch=4.94e-5, hindlegL1_epoch=5.01e-5, train_loss_epoch=4.75e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.27it/s]\u001b[A\n",
            "Epoch 15: 100% 200/200 [00:40<00:00,  4.95it/s, head1_step=3.9e-5, thorax1_step=3.81e-5, abdomen1_step=3.02e-5, forelegR1_step=3.06e-5, forelegL1_step=1.3e-5, midlegR1_step=1.62e-5, midlegL1_step=1.25e-5, hindlegR1_step=0.00018, hindlegL1_step=8.05e-5, train_loss_step=4.89e-5, learning_rate_step=0.0001, val_loss_step=7.6e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.35e-5, head1_epoch=5.51e-5, thorax1_epoch=3.97e-5, abdomen1_epoch=5.01e-5, forelegR1_epoch=4.43e-5, forelegL1_epoch=3.45e-5, midlegR1_epoch=3.21e-5, midlegL1_epoch=7.7e-5, hindlegR1_epoch=4.71e-5, hindlegL1_epoch=5.07e-5, train_loss_epoch=4.78e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.53it/s]\u001b[A\n",
            "Epoch 16: 100% 200/200 [00:44<00:00,  4.47it/s, head1_step=4.82e-5, thorax1_step=2.8e-5, abdomen1_step=4.52e-5, forelegR1_step=1.16e-5, forelegL1_step=1.77e-5, midlegR1_step=1.79e-5, midlegL1_step=0.00014, hindlegR1_step=3.05e-5, hindlegL1_step=7.38e-5, train_loss_step=4.59e-5, learning_rate_step=0.0001, val_loss_step=0.0001, learning_rate_epoch=0.0001, val_loss_epoch=0.000112, head1_epoch=5.24e-5, thorax1_epoch=3.96e-5, abdomen1_epoch=4.49e-5, forelegR1_epoch=3.77e-5, forelegL1_epoch=3.51e-5, midlegR1_epoch=3.44e-5, midlegL1_epoch=7.11e-5, hindlegR1_epoch=4.35e-5, hindlegL1_epoch=3.97e-5, train_loss_epoch=4.43e-5]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.22it/s]\u001b[A\n",
            "Epoch 17: 100% 200/200 [00:41<00:00,  4.82it/s, head1_step=3.09e-5, thorax1_step=3.03e-5, abdomen1_step=2.41e-5, forelegR1_step=1.38e-5, forelegL1_step=1.67e-5, midlegR1_step=6.47e-5, midlegL1_step=6.08e-6, hindlegR1_step=1.52e-5, hindlegL1_step=2.34e-5, train_loss_step=2.5e-5, learning_rate_step=0.0001, val_loss_step=7.14e-5, learning_rate_epoch=0.0001, val_loss_epoch=8.56e-5, head1_epoch=4.94e-5, thorax1_epoch=4.01e-5, abdomen1_epoch=4.48e-5, forelegR1_epoch=3.52e-5, forelegL1_epoch=3.51e-5, midlegR1_epoch=3.17e-5, midlegL1_epoch=7.03e-5, hindlegR1_epoch=4.28e-5, hindlegL1_epoch=4e-5, train_loss_epoch=4.33e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.91it/s]\u001b[A\n",
            "Epoch 18: 100% 200/200 [00:39<00:00,  5.02it/s, head1_step=2.9e-5, thorax1_step=2.69e-5, abdomen1_step=2.89e-5, forelegR1_step=1.52e-5, forelegL1_step=1.58e-5, midlegR1_step=4.51e-5, midlegL1_step=3.02e-5, hindlegR1_step=7.55e-5, hindlegL1_step=7.94e-6, train_loss_step=3.05e-5, learning_rate_step=0.0001, val_loss_step=8.91e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.29e-5, head1_epoch=4.11e-5, thorax1_epoch=3.38e-5, abdomen1_epoch=4.07e-5, forelegR1_epoch=3.56e-5, forelegL1_epoch=2.72e-5, midlegR1_epoch=2.83e-5, midlegL1_epoch=6.37e-5, hindlegR1_epoch=4.06e-5, hindlegL1_epoch=3.28e-5, train_loss_epoch=3.82e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.70it/s]\u001b[A\n",
            "Epoch 19: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=1.99e-5, thorax1_step=2.24e-5, abdomen1_step=2.39e-5, forelegR1_step=8.36e-6, forelegL1_step=0.000247, midlegR1_step=2.22e-5, midlegL1_step=5.82e-6, hindlegR1_step=4.51e-5, hindlegL1_step=6.24e-6, train_loss_step=4.45e-5, learning_rate_step=0.0001, val_loss_step=0.000102, learning_rate_epoch=0.0001, val_loss_epoch=0.000102, head1_epoch=3.8e-5, thorax1_epoch=3.07e-5, abdomen1_epoch=3.78e-5, forelegR1_epoch=3.24e-5, forelegL1_epoch=2.57e-5, midlegR1_epoch=2.77e-5, midlegL1_epoch=5.8e-5, hindlegR1_epoch=3.7e-5, hindlegL1_epoch=2.86e-5, train_loss_epoch=3.51e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.18it/s]\u001b[A\n",
            "Epoch 20: 100% 200/200 [00:40<00:00,  4.99it/s, head1_step=3.36e-5, thorax1_step=1.69e-5, abdomen1_step=2.15e-5, forelegR1_step=1.27e-5, forelegL1_step=1.06e-5, midlegR1_step=5.09e-6, midlegL1_step=2.15e-5, hindlegR1_step=2.52e-5, hindlegL1_step=9.4e-6, train_loss_step=1.74e-5, learning_rate_step=0.0001, val_loss_step=6.38e-5, learning_rate_epoch=0.0001, val_loss_epoch=8.51e-5, head1_epoch=3.63e-5, thorax1_epoch=2.96e-5, abdomen1_epoch=3.34e-5, forelegR1_epoch=3.18e-5, forelegL1_epoch=2.26e-5, midlegR1_epoch=2.04e-5, midlegL1_epoch=4.96e-5, hindlegR1_epoch=2.62e-5, hindlegL1_epoch=2.24e-5, train_loss_epoch=3.02e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.87it/s]\u001b[A\n",
            "Epoch 21: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=4.71e-5, thorax1_step=3.14e-5, abdomen1_step=5.7e-5, forelegR1_step=3.33e-6, forelegL1_step=2.03e-5, midlegR1_step=1.47e-5, midlegL1_step=8.25e-5, hindlegR1_step=0.000187, hindlegL1_step=0.000277, train_loss_step=8e-5, learning_rate_step=0.0001, val_loss_step=7.15e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.42e-5, head1_epoch=3.33e-5, thorax1_epoch=2.75e-5, abdomen1_epoch=3.08e-5, forelegR1_epoch=3.22e-5, forelegL1_epoch=1.95e-5, midlegR1_epoch=1.44e-5, midlegL1_epoch=4.55e-5, hindlegR1_epoch=2.1e-5, hindlegL1_epoch=1.81e-5, train_loss_epoch=2.69e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.24it/s]\u001b[A\n",
            "Epoch 22: 100% 200/200 [00:38<00:00,  5.15it/s, head1_step=1.15e-5, thorax1_step=2.16e-5, abdomen1_step=3.53e-5, forelegR1_step=1.92e-5, forelegL1_step=1.1e-5, midlegR1_step=4.96e-6, midlegL1_step=1.1e-5, hindlegR1_step=8.15e-6, hindlegL1_step=3e-6, train_loss_step=1.4e-5, learning_rate_step=0.0001, val_loss_step=0.000111, learning_rate_epoch=0.0001, val_loss_epoch=0.000107, head1_epoch=3.27e-5, thorax1_epoch=2.74e-5, abdomen1_epoch=3.2e-5, forelegR1_epoch=2.94e-5, forelegL1_epoch=2.17e-5, midlegR1_epoch=1.36e-5, midlegL1_epoch=4.77e-5, hindlegR1_epoch=1.99e-5, hindlegL1_epoch=2.1e-5, train_loss_epoch=2.73e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.80it/s]\u001b[A\n",
            "Epoch 23: 100% 200/200 [00:39<00:00,  5.10it/s, head1_step=3.46e-5, thorax1_step=1.25e-5, abdomen1_step=3.38e-5, forelegR1_step=4.87e-6, forelegL1_step=1.28e-5, midlegR1_step=1.57e-5, midlegL1_step=1.2e-5, hindlegR1_step=1.09e-5, hindlegL1_step=5.14e-6, train_loss_step=1.58e-5, learning_rate_step=0.0001, val_loss_step=9.49e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.99e-5, head1_epoch=3.46e-5, thorax1_epoch=3.03e-5, abdomen1_epoch=3.72e-5, forelegR1_epoch=2.79e-5, forelegL1_epoch=2.2e-5, midlegR1_epoch=1.84e-5, midlegL1_epoch=5.45e-5, hindlegR1_epoch=2.31e-5, hindlegL1_epoch=3.15e-5, train_loss_epoch=3.11e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.87it/s]\u001b[A\n",
            "Epoch 24: 100% 200/200 [00:39<00:00,  5.12it/s, head1_step=2.7e-5, thorax1_step=1.36e-5, abdomen1_step=2.19e-5, forelegR1_step=4e-6, forelegL1_step=9.63e-6, midlegR1_step=1.19e-5, midlegL1_step=6.06e-5, hindlegR1_step=1.16e-5, hindlegL1_step=6.21e-6, train_loss_step=1.85e-5, learning_rate_step=0.0001, val_loss_step=9.73e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.77e-5, head1_epoch=3.25e-5, thorax1_epoch=2.55e-5, abdomen1_epoch=3.26e-5, forelegR1_epoch=2.47e-5, forelegL1_epoch=2.09e-5, midlegR1_epoch=1.23e-5, midlegL1_epoch=4.06e-5, hindlegR1_epoch=1.61e-5, hindlegL1_epoch=1.89e-5, train_loss_epoch=2.49e-5]    \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.73it/s]\u001b[A\n",
            "Epoch 25: 100% 200/200 [00:39<00:00,  5.08it/s, head1_step=1.88e-5, thorax1_step=2.08e-5, abdomen1_step=3.61e-5, forelegR1_step=6.32e-6, forelegL1_step=6.89e-6, midlegR1_step=6.53e-6, midlegL1_step=2.63e-5, hindlegR1_step=1.96e-5, hindlegL1_step=1.17e-5, train_loss_step=1.7e-5, learning_rate_step=0.0001, val_loss_step=7.39e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.14e-5, head1_epoch=3.27e-5, thorax1_epoch=2.45e-5, abdomen1_epoch=2.99e-5, forelegR1_epoch=2.54e-5, forelegL1_epoch=1.95e-5, midlegR1_epoch=1.21e-5, midlegL1_epoch=3.71e-5, hindlegR1_epoch=1.15e-5, hindlegL1_epoch=1.37e-5, train_loss_epoch=2.29e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.93it/s]\u001b[A\n",
            "Epoch 26: 100% 200/200 [00:39<00:00,  5.08it/s, head1_step=3.95e-5, thorax1_step=2.32e-5, abdomen1_step=3.6e-5, forelegR1_step=8.17e-6, forelegL1_step=7.36e-6, midlegR1_step=1.19e-5, midlegL1_step=1.68e-5, hindlegR1_step=3e-5, hindlegL1_step=3.79e-6, train_loss_step=1.96e-5, learning_rate_step=0.0001, val_loss_step=7.79e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000101, head1_epoch=3.25e-5, thorax1_epoch=2.54e-5, abdomen1_epoch=2.93e-5, forelegR1_epoch=2.41e-5, forelegL1_epoch=2.21e-5, midlegR1_epoch=1.25e-5, midlegL1_epoch=4e-5, hindlegR1_epoch=1.64e-5, hindlegL1_epoch=2.11e-5, train_loss_epoch=2.48e-5]       \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.34it/s]\u001b[A\n",
            "Epoch 27: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=2.83e-5, thorax1_step=2.75e-5, abdomen1_step=4.86e-5, forelegR1_step=9.91e-6, forelegL1_step=1.68e-5, midlegR1_step=6.83e-6, midlegL1_step=1.28e-5, hindlegR1_step=2.87e-6, hindlegL1_step=9.88e-6, train_loss_step=1.82e-5, learning_rate_step=0.0001, val_loss_step=9.12e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.61e-5, head1_epoch=3.48e-5, thorax1_epoch=2.58e-5, abdomen1_epoch=3.08e-5, forelegR1_epoch=2.73e-5, forelegL1_epoch=2.18e-5, midlegR1_epoch=1.87e-5, midlegL1_epoch=4.49e-5, hindlegR1_epoch=1.84e-5, hindlegL1_epoch=1.86e-5, train_loss_epoch=2.68e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.04it/s]\u001b[A\n",
            "Epoch 28: 100% 200/200 [00:39<00:00,  5.11it/s, head1_step=3.85e-5, thorax1_step=1.23e-5, abdomen1_step=3.4e-5, forelegR1_step=1.33e-5, forelegL1_step=1.02e-5, midlegR1_step=1.39e-5, midlegL1_step=1.72e-5, hindlegR1_step=1.23e-5, hindlegL1_step=5.84e-6, train_loss_step=1.75e-5, learning_rate_step=0.0001, val_loss_step=7.7e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.93e-5, head1_epoch=2.86e-5, thorax1_epoch=2.57e-5, abdomen1_epoch=2.88e-5, forelegR1_epoch=2.35e-5, forelegL1_epoch=2.05e-5, midlegR1_epoch=1.21e-5, midlegL1_epoch=3.47e-5, hindlegR1_epoch=1.24e-5, hindlegL1_epoch=1.75e-5, train_loss_epoch=2.27e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.06it/s]\u001b[A\n",
            "Epoch 29: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=1.26e-5, thorax1_step=2.94e-5, abdomen1_step=1.41e-5, forelegR1_step=9.22e-6, forelegL1_step=9.85e-6, midlegR1_step=8.47e-6, midlegL1_step=4.62e-6, hindlegR1_step=5.21e-6, hindlegL1_step=2.69e-6, train_loss_step=1.07e-5, learning_rate_step=0.0001, val_loss_step=5.96e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.0001, head1_epoch=2.91e-5, thorax1_epoch=2.5e-5, abdomen1_epoch=3e-5, forelegR1_epoch=2.39e-5, forelegL1_epoch=2.09e-5, midlegR1_epoch=1.08e-5, midlegL1_epoch=3.88e-5, hindlegR1_epoch=1.14e-5, hindlegL1_epoch=2.17e-5, train_loss_epoch=2.35e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.33it/s]\u001b[A\n",
            "Epoch 30: 100% 200/200 [00:38<00:00,  5.16it/s, head1_step=2.15e-5, thorax1_step=1.58e-5, abdomen1_step=2.01e-5, forelegR1_step=1.13e-5, forelegL1_step=3.07e-6, midlegR1_step=4.29e-6, midlegL1_step=1.28e-5, hindlegR1_step=4.22e-6, hindlegL1_step=3.1e-6, train_loss_step=1.07e-5, learning_rate_step=0.0001, val_loss_step=8.17e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000102, head1_epoch=2.57e-5, thorax1_epoch=1.95e-5, abdomen1_epoch=2.33e-5, forelegR1_epoch=1.85e-5, forelegL1_epoch=1.53e-5, midlegR1_epoch=7.39e-6, midlegL1_epoch=3.51e-5, hindlegR1_epoch=7e-6, hindlegL1_epoch=1.78e-5, train_loss_epoch=1.88e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.10it/s]\u001b[A\n",
            "Epoch 31: 100% 200/200 [00:39<00:00,  5.11it/s, head1_step=1.69e-5, thorax1_step=1.89e-5, abdomen1_step=1.59e-5, forelegR1_step=0.000379, forelegL1_step=8.65e-5, midlegR1_step=8.25e-6, midlegL1_step=0.000175, hindlegR1_step=3.24e-6, hindlegL1_step=6.57e-6, train_loss_step=7.89e-5, learning_rate_step=0.0001, val_loss_step=8.05e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.26e-5, head1_epoch=2.3e-5, thorax1_epoch=1.73e-5, abdomen1_epoch=1.99e-5, forelegR1_epoch=1.8e-5, forelegL1_epoch=1.52e-5, midlegR1_epoch=6.81e-6, midlegL1_epoch=2.52e-5, hindlegR1_epoch=6.07e-6, hindlegL1_epoch=5.86e-6, train_loss_epoch=1.53e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.87it/s]\u001b[A\n",
            "Epoch 32: 100% 200/200 [00:39<00:00,  5.10it/s, head1_step=1.01e-5, thorax1_step=9.21e-6, abdomen1_step=1.67e-5, forelegR1_step=7.96e-6, forelegL1_step=3.5e-6, midlegR1_step=3.96e-6, midlegL1_step=6.38e-6, hindlegR1_step=2.9e-6, hindlegL1_step=4.86e-6, train_loss_step=7.28e-6, learning_rate_step=0.0001, val_loss_step=8.37e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000103, head1_epoch=2.32e-5, thorax1_epoch=1.67e-5, abdomen1_epoch=1.89e-5, forelegR1_epoch=2.27e-5, forelegL1_epoch=1.46e-5, midlegR1_epoch=7.42e-6, midlegL1_epoch=2.14e-5, hindlegR1_epoch=5.54e-6, hindlegL1_epoch=4.63e-6, train_loss_epoch=1.5e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.06it/s]\u001b[A\n",
            "Epoch 33: 100% 200/200 [00:39<00:00,  5.12it/s, head1_step=2.1e-5, thorax1_step=2.64e-5, abdomen1_step=1.7e-5, forelegR1_step=6.89e-6, forelegL1_step=4.26e-6, midlegR1_step=6.32e-6, midlegL1_step=5.33e-6, hindlegR1_step=4.42e-6, hindlegL1_step=2.31e-6, train_loss_step=1.04e-5, learning_rate_step=0.0001, val_loss_step=7.85e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.95e-5, head1_epoch=2.27e-5, thorax1_epoch=1.65e-5, abdomen1_epoch=1.95e-5, forelegR1_epoch=1.89e-5, forelegL1_epoch=1.71e-5, midlegR1_epoch=6.84e-6, midlegL1_epoch=2.1e-5, hindlegR1_epoch=6.72e-6, hindlegL1_epoch=4.8e-6, train_loss_epoch=1.49e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.03it/s]\u001b[A\n",
            "Epoch 34: 100% 200/200 [00:39<00:00,  5.07it/s, head1_step=1.75e-5, thorax1_step=1.15e-5, abdomen1_step=1.16e-5, forelegR1_step=6.29e-6, forelegL1_step=9.76e-6, midlegR1_step=1.39e-5, midlegL1_step=2.74e-6, hindlegR1_step=2.59e-6, hindlegL1_step=7.34e-6, train_loss_step=9.24e-6, learning_rate_step=0.0001, val_loss_step=7.74e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.7e-5, head1_epoch=2.03e-5, thorax1_epoch=1.54e-5, abdomen1_epoch=1.85e-5, forelegR1_epoch=1.42e-5, forelegL1_epoch=1.31e-5, midlegR1_epoch=5.04e-6, midlegL1_epoch=1.97e-5, hindlegR1_epoch=4.84e-6, hindlegL1_epoch=3.65e-6, train_loss_epoch=1.27e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.93it/s]\u001b[A\n",
            "Epoch 35: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=3.11e-5, thorax1_step=1.67e-5, abdomen1_step=1.64e-5, forelegR1_step=1.12e-5, forelegL1_step=2.71e-5, midlegR1_step=2.11e-5, midlegL1_step=6.54e-6, hindlegR1_step=1.39e-5, hindlegL1_step=4.83e-6, train_loss_step=1.65e-5, learning_rate_step=0.0001, val_loss_step=7.56e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.0001, head1_epoch=2.07e-5, thorax1_epoch=1.55e-5, abdomen1_epoch=1.85e-5, forelegR1_epoch=1.34e-5, forelegL1_epoch=1.08e-5, midlegR1_epoch=6.51e-6, midlegL1_epoch=1.75e-5, hindlegR1_epoch=4.5e-6, hindlegL1_epoch=4.29e-6, train_loss_epoch=1.24e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.03it/s]\u001b[A\n",
            "Epoch 36: 100% 200/200 [00:38<00:00,  5.13it/s, head1_step=9.58e-6, thorax1_step=1.19e-5, abdomen1_step=1.17e-5, forelegR1_step=2.46e-6, forelegL1_step=0.000183, midlegR1_step=1.23e-5, midlegL1_step=2.96e-6, hindlegR1_step=4.18e-6, hindlegL1_step=2.15e-6, train_loss_step=2.67e-5, learning_rate_step=0.0001, val_loss_step=7.82e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000104, head1_epoch=2.77e-5, thorax1_epoch=2.17e-5, abdomen1_epoch=2.41e-5, forelegR1_epoch=2e-5, forelegL1_epoch=1.8e-5, midlegR1_epoch=1.74e-5, midlegL1_epoch=2.3e-5, hindlegR1_epoch=1.09e-5, hindlegL1_epoch=1e-5, train_loss_epoch=1.92e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  9.32it/s]\u001b[A\n",
            "Epoch 37: 100% 200/200 [00:39<00:00,  5.10it/s, head1_step=1.98e-5, thorax1_step=1.3e-5, abdomen1_step=7.51e-6, forelegR1_step=1.35e-5, forelegL1_step=3.9e-6, midlegR1_step=2.22e-6, midlegL1_step=9.36e-6, hindlegR1_step=2.12e-6, hindlegL1_step=5.42e-6, train_loss_step=8.54e-6, learning_rate_step=0.0001, val_loss_step=8.37e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000101, head1_epoch=2.85e-5, thorax1_epoch=2.09e-5, abdomen1_epoch=2.52e-5, forelegR1_epoch=2.05e-5, forelegL1_epoch=1.56e-5, midlegR1_epoch=1.41e-5, midlegL1_epoch=3.13e-5, hindlegR1_epoch=1.56e-5, hindlegL1_epoch=1.97e-5, train_loss_epoch=2.13e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.63it/s]\u001b[A\n",
            "Epoch 38: 100% 200/200 [00:39<00:00,  5.07it/s, head1_step=2.21e-5, thorax1_step=9.45e-6, abdomen1_step=1.52e-5, forelegR1_step=2.14e-6, forelegL1_step=2.96e-6, midlegR1_step=3.41e-6, midlegL1_step=8.9e-6, hindlegR1_step=4.61e-6, hindlegL1_step=2.38e-5, train_loss_step=1.03e-5, learning_rate_step=0.0001, val_loss_step=8.04e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000103, head1_epoch=2.28e-5, thorax1_epoch=1.64e-5, abdomen1_epoch=2.11e-5, forelegR1_epoch=1.47e-5, forelegL1_epoch=9.29e-6, midlegR1_epoch=7.85e-6, midlegL1_epoch=2.11e-5, hindlegR1_epoch=5.9e-6, hindlegL1_epoch=1.14e-5, train_loss_epoch=1.45e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Epoch 39: 100% 200/200 [00:39<00:00,  5.05it/s, head1_step=1.53e-5, thorax1_step=7.91e-6, abdomen1_step=2.14e-5, forelegR1_step=3.51e-6, forelegL1_step=6.77e-6, midlegR1_step=5.27e-6, midlegL1_step=4.53e-6, hindlegR1_step=3.27e-6, hindlegL1_step=2.41e-6, train_loss_step=7.82e-6, learning_rate_step=0.0001, val_loss_step=8.52e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.84e-5, head1_epoch=2.88e-5, thorax1_epoch=2.04e-5, abdomen1_epoch=2.29e-5, forelegR1_epoch=1.6e-5, forelegL1_epoch=2.81e-5, midlegR1_epoch=8.15e-6, midlegL1_epoch=4.25e-5, hindlegR1_epoch=8.82e-6, hindlegL1_epoch=2.04e-5, train_loss_epoch=2.18e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.95it/s]\u001b[A\n",
            "Epoch 40: 100% 200/200 [00:39<00:00,  5.06it/s, head1_step=3.93e-5, thorax1_step=7.2e-6, abdomen1_step=1.98e-5, forelegR1_step=3.39e-6, forelegL1_step=8.46e-6, midlegR1_step=9.39e-6, midlegL1_step=2.69e-6, hindlegR1_step=3.15e-6, hindlegL1_step=4.31e-6, train_loss_step=1.08e-5, learning_rate_step=0.0001, val_loss_step=7.13e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.96e-5, head1_epoch=1.94e-5, thorax1_epoch=1.49e-5, abdomen1_epoch=1.86e-5, forelegR1_epoch=1.28e-5, forelegL1_epoch=1.73e-5, midlegR1_epoch=6.44e-6, midlegL1_epoch=2.97e-5, hindlegR1_epoch=4.78e-6, hindlegL1_epoch=8.23e-6, train_loss_epoch=1.47e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.97it/s]\u001b[A\n",
            "Epoch 41: 100% 200/200 [00:40<00:00,  4.95it/s, head1_step=2.05e-5, thorax1_step=8.52e-6, abdomen1_step=2.1e-5, forelegR1_step=7.19e-6, forelegL1_step=4.38e-6, midlegR1_step=6.47e-6, midlegL1_step=0.00014, hindlegR1_step=6.58e-6, hindlegL1_step=1.5e-6, train_loss_step=2.4e-5, learning_rate_step=0.0001, val_loss_step=7.79e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000112, head1_epoch=2.21e-5, thorax1_epoch=1.4e-5, abdomen1_epoch=1.89e-5, forelegR1_epoch=1.19e-5, forelegL1_epoch=1.49e-5, midlegR1_epoch=6.5e-6, midlegL1_epoch=2.37e-5, hindlegR1_epoch=4.12e-6, hindlegL1_epoch=3.1e-6, train_loss_epoch=1.33e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.86it/s]\u001b[A\n",
            "Epoch 42: 100% 200/200 [00:39<00:00,  5.06it/s, head1_step=7.24e-6, thorax1_step=1.14e-5, abdomen1_step=1.61e-5, forelegR1_step=2.6e-6, forelegL1_step=5.58e-6, midlegR1_step=2.69e-6, midlegL1_step=7.22e-6, hindlegR1_step=2.81e-6, hindlegL1_step=2.91e-6, train_loss_step=6.5e-6, learning_rate_step=0.0001, val_loss_step=7.98e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000106, head1_epoch=2.62e-5, thorax1_epoch=1.37e-5, abdomen1_epoch=2.22e-5, forelegR1_epoch=1.25e-5, forelegL1_epoch=1.47e-5, midlegR1_epoch=9.11e-6, midlegL1_epoch=2.43e-5, hindlegR1_epoch=5.96e-6, hindlegL1_epoch=3.9e-6, train_loss_epoch=1.47e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.96it/s]\u001b[A\n",
            "Epoch 43: 100% 200/200 [00:39<00:00,  5.10it/s, head1_step=2.1e-5, thorax1_step=2.34e-5, abdomen1_step=1.78e-5, forelegR1_step=4.69e-6, forelegL1_step=8.12e-6, midlegR1_step=8.15e-6, midlegL1_step=8.08e-6, hindlegR1_step=1.44e-5, hindlegL1_step=1.28e-5, train_loss_step=1.32e-5, learning_rate_step=0.0001, val_loss_step=7.68e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000108, head1_epoch=1.84e-5, thorax1_epoch=1.62e-5, abdomen1_epoch=1.96e-5, forelegR1_epoch=1.22e-5, forelegL1_epoch=1.42e-5, midlegR1_epoch=1.02e-5, midlegL1_epoch=2.24e-5, hindlegR1_epoch=6.56e-6, hindlegL1_epoch=4.64e-6, train_loss_epoch=1.38e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.92it/s]\u001b[A\n",
            "Epoch 44: 100% 200/200 [00:39<00:00,  5.07it/s, head1_step=2.54e-5, thorax1_step=4.72e-6, abdomen1_step=1.86e-5, forelegR1_step=4.96e-6, forelegL1_step=7.34e-6, midlegR1_step=6.76e-6, midlegL1_step=5.16e-6, hindlegR1_step=2.56e-6, hindlegL1_step=4.3e-6, train_loss_step=8.86e-6, learning_rate_step=0.0001, val_loss_step=0.000115, learning_rate_epoch=0.0001, val_loss_epoch=0.000104, head1_epoch=2.07e-5, thorax1_epoch=1.64e-5, abdomen1_epoch=1.95e-5, forelegR1_epoch=1.77e-5, forelegL1_epoch=1.52e-5, midlegR1_epoch=1.02e-5, midlegL1_epoch=2.42e-5, hindlegR1_epoch=7.17e-6, hindlegL1_epoch=9.47e-6, train_loss_epoch=1.56e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.84it/s]\u001b[A\n",
            "Epoch 45: 100% 200/200 [00:39<00:00,  5.09it/s, head1_step=1.37e-5, thorax1_step=8.7e-6, abdomen1_step=2.54e-5, forelegR1_step=3.84e-6, forelegL1_step=2.19e-6, midlegR1_step=5.6e-6, midlegL1_step=2.74e-6, hindlegR1_step=7.25e-6, hindlegL1_step=1.75e-6, train_loss_step=7.91e-6, learning_rate_step=0.0001, val_loss_step=8.59e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.73e-5, head1_epoch=2.48e-5, thorax1_epoch=2.06e-5, abdomen1_epoch=2.44e-5, forelegR1_epoch=1.98e-5, forelegL1_epoch=1.63e-5, midlegR1_epoch=1.24e-5, midlegL1_epoch=3.98e-5, hindlegR1_epoch=1.02e-5, hindlegL1_epoch=2.55e-5, train_loss_epoch=2.15e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.82it/s]\u001b[A\n",
            "Epoch 46: 100% 200/200 [00:39<00:00,  5.11it/s, head1_step=1.25e-5, thorax1_step=1.06e-5, abdomen1_step=1.35e-5, forelegR1_step=7.5e-6, forelegL1_step=5.6e-6, midlegR1_step=9.15e-6, midlegL1_step=4.36e-6, hindlegR1_step=8.23e-6, hindlegL1_step=2.43e-6, train_loss_step=8.21e-6, learning_rate_step=0.0001, val_loss_step=8.5e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000111, head1_epoch=1.88e-5, thorax1_epoch=1.51e-5, abdomen1_epoch=1.88e-5, forelegR1_epoch=1.25e-5, forelegL1_epoch=1.11e-5, midlegR1_epoch=7.38e-6, midlegL1_epoch=1.39e-5, hindlegR1_epoch=1.37e-5, hindlegL1_epoch=3.93e-6, train_loss_epoch=1.28e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.81it/s]\u001b[A\n",
            "Epoch 47: 100% 200/200 [00:39<00:00,  5.12it/s, head1_step=1.97e-5, thorax1_step=1.83e-5, abdomen1_step=1.66e-5, forelegR1_step=1.97e-5, forelegL1_step=9.52e-6, midlegR1_step=1.08e-5, midlegL1_step=1.65e-5, hindlegR1_step=1.93e-5, hindlegL1_step=3.58e-6, train_loss_step=1.49e-5, learning_rate_step=0.0001, val_loss_step=9.7e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000107, head1_epoch=2.12e-5, thorax1_epoch=1.73e-5, abdomen1_epoch=2.13e-5, forelegR1_epoch=1.35e-5, forelegL1_epoch=1.22e-5, midlegR1_epoch=8.59e-6, midlegL1_epoch=1.47e-5, hindlegR1_epoch=9.18e-6, hindlegL1_epoch=4.88e-6, train_loss_epoch=1.36e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:00<00:00,  8.99it/s]\u001b[A\n",
            "Epoch 48: 100% 200/200 [00:39<00:00,  5.08it/s, head1_step=6.53e-6, thorax1_step=1.38e-5, abdomen1_step=1.12e-5, forelegR1_step=0.000361, forelegL1_step=6.37e-6, midlegR1_step=6.93e-6, midlegL1_step=8.03e-6, hindlegR1_step=2.74e-6, hindlegL1_step=2.09e-6, train_loss_step=4.65e-5, learning_rate_step=0.0001, val_loss_step=8.05e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.0001, head1_epoch=2.76e-5, thorax1_epoch=1.84e-5, abdomen1_epoch=2.24e-5, forelegR1_epoch=1.63e-5, forelegL1_epoch=1.67e-5, midlegR1_epoch=1.46e-5, midlegL1_epoch=1.88e-5, hindlegR1_epoch=1.04e-5, hindlegL1_epoch=6.44e-6, train_loss_epoch=1.69e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.41it/s]\u001b[A\n",
            "Epoch 49: 100% 200/200 [00:39<00:00,  5.07it/s, head1_step=1.46e-5, thorax1_step=6.62e-6, abdomen1_step=1.69e-5, forelegR1_step=3.18e-6, forelegL1_step=2.17e-6, midlegR1_step=2.36e-6, midlegL1_step=2.4e-6, hindlegR1_step=2.76e-6, hindlegL1_step=3.69e-6, train_loss_step=6.08e-6, learning_rate_step=0.0001, val_loss_step=9e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000105, head1_epoch=2e-5, thorax1_epoch=1.14e-5, abdomen1_epoch=1.5e-5, forelegR1_epoch=1.19e-5, forelegL1_epoch=9.52e-6, midlegR1_epoch=7.34e-6, midlegL1_epoch=1.48e-5, hindlegR1_epoch=6.3e-6, hindlegL1_epoch=4.11e-6, train_loss_epoch=1.12e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Epoch 49: 100% 200/200 [00:41<00:00,  4.80it/s, head1_step=1.46e-5, thorax1_step=6.62e-6, abdomen1_step=1.69e-5, forelegR1_step=3.18e-6, forelegL1_step=2.17e-6, midlegR1_step=2.36e-6, midlegL1_step=2.4e-6, hindlegR1_step=2.76e-6, hindlegL1_step=3.69e-6, train_loss_step=6.08e-6, learning_rate_step=0.0001, val_loss_step=7.6e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000102, head1_epoch=1.52e-5, thorax1_epoch=8.58e-6, abdomen1_epoch=1.23e-5, forelegR1_epoch=6.97e-6, forelegL1_epoch=5.31e-6, midlegR1_epoch=3.66e-6, midlegL1_epoch=1.13e-5, hindlegR1_epoch=3.34e-6, hindlegL1_epoch=2.46e-6, train_loss_epoch=7.68e-6]\n",
            "2025-10-19 10:34:59 | INFO | sleap_nn.training.model_trainer:train:1037 | Finished training loop. [34.8 min]\n",
            "2025-10-19 10:34:59 | INFO | sleap_nn.training.model_trainer:train:1064 | Deleting viz folder at models/drosophila_unet_1_251019_094425/drosophila_unet_1_251019_094425/viz...\n",
            "INFO:sleap.legacy_cli_adaptors:Finished training at: 2025-10-19 10:35:00.068260\n",
            "INFO:sleap.legacy_cli_adaptors:Total training time: 2088.582635641098 secs\n",
            "INFO:sleap.legacy_cli_adaptors:Training Config: data_config:\n",
            "  train_labels_path:\n",
            "  - colab.pkg.slp\n",
            "  val_labels_path: null\n",
            "  validation_fraction: 0.1\n",
            "  test_file_path: null\n",
            "  provider: LabelsReader\n",
            "  user_instances_only: true\n",
            "  data_pipeline_fw: torch_dataset\n",
            "  cache_img_path: null\n",
            "  use_existing_imgs: false\n",
            "  delete_cache_imgs_after_training: true\n",
            "  preprocessing:\n",
            "    ensure_rgb: true\n",
            "    ensure_grayscale: false\n",
            "    max_height: 182\n",
            "    max_width: 682\n",
            "    scale: 1.0\n",
            "    crop_size: null\n",
            "    min_crop_size: 100\n",
            "  use_augmentations_train: false\n",
            "  augmentation_config:\n",
            "    intensity:\n",
            "      uniform_noise_min: 0.0\n",
            "      uniform_noise_max: 1.0\n",
            "      uniform_noise_p: 0.0\n",
            "      gaussian_noise_mean: 5.0\n",
            "      gaussian_noise_std: 0.0\n",
            "      gaussian_noise_p: 0.0\n",
            "      contrast_min: 0.5\n",
            "      contrast_max: 1.75\n",
            "      contrast_p: 0.0\n",
            "      brightness_min: 0.0\n",
            "      brightness_max: 2.0\n",
            "      brightness_p: 0.0\n",
            "    geometric:\n",
            "      rotation_min: -15.0\n",
            "      rotation_max: 15.0\n",
            "      scale_min: 0.9\n",
            "      scale_max: 1.1\n",
            "      translate_width: 0.0\n",
            "      translate_height: 0.0\n",
            "      affine_p: 1.0\n",
            "      erase_scale_min: 0.0001\n",
            "      erase_scale_max: 0.01\n",
            "      erase_ratio_min: 1.0\n",
            "      erase_ratio_max: 1.0\n",
            "      erase_p: 0.0\n",
            "      mixup_lambda_min: 0.01\n",
            "      mixup_lambda_max: 0.05\n",
            "      mixup_p: 0.0\n",
            "  skeletons:\n",
            "  - nodes:\n",
            "    - name: head1\n",
            "    - name: thorax1\n",
            "    - name: abdomen1\n",
            "    - name: forelegR1\n",
            "    - name: forelegL1\n",
            "    - name: midlegR1\n",
            "    - name: midlegL1\n",
            "    - name: hindlegR1\n",
            "    - name: hindlegL1\n",
            "    edges:\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: head1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: abdomen1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: forelegR1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: forelegL1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: midlegR1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: midlegL1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: hindlegR1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: hindlegL1\n",
            "    symmetries:\n",
            "    - - name: forelegR1\n",
            "      - name: forelegL1\n",
            "    - - name: midlegL1\n",
            "      - name: midlegR1\n",
            "    - - name: hindlegL1\n",
            "      - name: hindlegR1\n",
            "    name: Skeleton-0\n",
            "model_config:\n",
            "  init_weights: default\n",
            "  pretrained_backbone_weights: null\n",
            "  pretrained_head_weights: null\n",
            "  backbone_config:\n",
            "    unet:\n",
            "      in_channels: 3\n",
            "      kernel_size: 3\n",
            "      filters: 32\n",
            "      filters_rate: 1.5\n",
            "      max_stride: 32\n",
            "      stem_stride: null\n",
            "      middle_block: true\n",
            "      up_interpolate: true\n",
            "      stacks: 1\n",
            "      convs_per_block: 2\n",
            "      output_stride: 4\n",
            "    convnext: null\n",
            "    swint: null\n",
            "  head_configs:\n",
            "    single_instance:\n",
            "      confmaps:\n",
            "        part_names:\n",
            "        - head1\n",
            "        - thorax1\n",
            "        - abdomen1\n",
            "        - forelegR1\n",
            "        - forelegL1\n",
            "        - midlegR1\n",
            "        - midlegL1\n",
            "        - hindlegR1\n",
            "        - hindlegL1\n",
            "        sigma: 2.5\n",
            "        output_stride: 4\n",
            "    centroid: null\n",
            "    centered_instance: null\n",
            "    bottomup: null\n",
            "    multi_class_bottomup: null\n",
            "    multi_class_topdown: null\n",
            "  total_params: 2936824\n",
            "trainer_config:\n",
            "  train_data_loader:\n",
            "    batch_size: 6\n",
            "    shuffle: false\n",
            "    num_workers: 0\n",
            "  val_data_loader:\n",
            "    batch_size: 6\n",
            "    shuffle: false\n",
            "    num_workers: 0\n",
            "  model_ckpt:\n",
            "    save_top_k: 1\n",
            "    save_last: false\n",
            "  trainer_devices: auto\n",
            "  trainer_device_indices: null\n",
            "  trainer_accelerator: auto\n",
            "  profiler: null\n",
            "  trainer_strategy: auto\n",
            "  enable_progress_bar: true\n",
            "  min_train_steps_per_epoch: 200\n",
            "  train_steps_per_epoch: 200\n",
            "  visualize_preds_during_training: true\n",
            "  keep_viz: false\n",
            "  max_epochs: 200\n",
            "  seed: null\n",
            "  use_wandb: false\n",
            "  save_ckpt: true\n",
            "  ckpt_dir: models/drosophila_unet_1_251019_094425\n",
            "  run_name: drosophila_unet_1_251019_094425\n",
            "  resume_ckpt_path: null\n",
            "  wandb:\n",
            "    entity: ''\n",
            "    project: ''\n",
            "    name: ''\n",
            "    save_viz_imgs_wandb: false\n",
            "    api_key: ''\n",
            "    wandb_mode: null\n",
            "    prv_runid: ''\n",
            "    group: ''\n",
            "    current_run_id: null\n",
            "  optimizer_name: Adam\n",
            "  optimizer:\n",
            "    lr: 0.0001\n",
            "    amsgrad: false\n",
            "  lr_scheduler: null\n",
            "  early_stopping:\n",
            "    min_delta: 1.0e-08\n",
            "    patience: 30\n",
            "    stop_training_on_plateau: true\n",
            "  online_hard_keypoint_mining:\n",
            "    online_mining: false\n",
            "    hard_to_easy_ratio: 2.0\n",
            "    min_hard_keypoints: 2\n",
            "    max_hard_keypoints: null\n",
            "    loss_scale: 5.0\n",
            "  zmq:\n",
            "    controller_port: null\n",
            "    controller_polling_timeout: 10\n",
            "    publish_port: null\n",
            "name: ''\n",
            "description: ''\n",
            "sleap_nn_version: 0.0.2\n",
            "filename: ''\n",
            "\n",
            "INFO:sleap.legacy_cli_adaptors:Training labels path for index 0: models/drosophila_unet_1_251019_094425/drosophila_unet_1_251019_094425\n",
            "2025-10-19 10:35:00 | INFO | sleap_nn.predict:run_inference:319 | Started inference at: 2025-10-19 10:35:00.731729\n",
            "2025-10-19 10:35:00 | INFO | sleap_nn.predict:run_inference:335 | Using device: cuda:0\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m407/407\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m Elapsed: \u001b[33m0:00:05\u001b[0m \u001b[31m75.9 FPS\u001b[0m\n",
            "\u001b[?25h2025-10-19 10:35:07 | INFO | sleap_nn.predict:run_inference:453 | Finished inference at: 2025-10-19 10:35:07.119575\n",
            "2025-10-19 10:35:07 | INFO | sleap_nn.predict:run_inference:454 | Total runtime: 6.387864828109741 secs\n",
            "2025-10-19 10:35:07 | INFO | sleap_nn.predict:run_inference:465 | Predictions output path: models/drosophila_unet_1_251019_094425/drosophila_unet_1_251019_094425/pred_train_0.slp\n",
            "2025-10-19 10:35:07 | INFO | sleap_nn.predict:run_inference:466 | Saved file at: 2025-10-19 10:35:07.237651\n",
            "INFO:sleap.legacy_cli_adaptors:---------Evaluation on `train_0` dataset---------\n",
            "INFO:sleap.legacy_cli_adaptors:OKS mAP: 0.9053310418177732\n",
            "INFO:sleap.legacy_cli_adaptors:Average distance: 1.3299788685478062\n",
            "INFO:sleap.legacy_cli_adaptors:p90 dist: 2.219273067190427\n",
            "INFO:sleap.legacy_cli_adaptors:p50 dist: 1.2314324135999555\n",
            "2025-10-19 10:35:07 | INFO | sleap_nn.predict:run_inference:319 | Started inference at: 2025-10-19 10:35:07.973072\n",
            "2025-10-19 10:35:07 | INFO | sleap_nn.predict:run_inference:335 | Using device: cuda:0\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m45/45\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m Elapsed: \u001b[33m0:00:00\u001b[0m \u001b[31m63.4 FPS\u001b[0m\n",
            "\u001b[?25h2025-10-19 10:35:09 | INFO | sleap_nn.predict:run_inference:453 | Finished inference at: 2025-10-19 10:35:09.153538\n",
            "2025-10-19 10:35:09 | INFO | sleap_nn.predict:run_inference:454 | Total runtime: 1.18048095703125 secs\n",
            "2025-10-19 10:35:09 | INFO | sleap_nn.predict:run_inference:465 | Predictions output path: models/drosophila_unet_1_251019_094425/drosophila_unet_1_251019_094425/pred_val_0.slp\n",
            "2025-10-19 10:35:09 | INFO | sleap_nn.predict:run_inference:466 | Saved file at: 2025-10-19 10:35:09.249326\n",
            "INFO:sleap.legacy_cli_adaptors:---------Evaluation on `val_0` dataset---------\n",
            "INFO:sleap.legacy_cli_adaptors:OKS mAP: 0.8230351501569952\n",
            "INFO:sleap.legacy_cli_adaptors:Average distance: 2.0526372059141913\n",
            "INFO:sleap.legacy_cli_adaptors:p90 dist: 2.5496590872597387\n",
            "INFO:sleap.legacy_cli_adaptors:p50 dist: 1.360729409100365\n"
          ]
        }
      ],
      "source": [
        "!sleap-train single_instance.yaml colab.pkg.slp\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result Files Generation"
      ],
      "metadata": {
        "id": "eGwiVzuu8-SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION\n",
        "# =========================================================\n",
        "MODELS_DIR = \"models\"   # parent folder containing model runs\n",
        "SAVE_FIGS = True        # save generated figures\n",
        "plt.rcParams.update({\"figure.dpi\": 120})\n",
        "\n",
        "# =========================================================\n",
        "# Locate latest model (by modification time)\n",
        "# =========================================================\n",
        "model_runs = sorted(glob.glob(os.path.join(MODELS_DIR, \"*\")), key=os.path.getmtime)\n",
        "if not model_runs:\n",
        "    raise FileNotFoundError(\"No model directories found in 'models/'. Check your path.\")\n",
        "latest_model = model_runs[-1]\n",
        "\n",
        "# Handle nested folder issue (model inside model)\n",
        "nested = os.path.join(latest_model, os.path.basename(latest_model))\n",
        "if os.path.isdir(nested):\n",
        "    print(f\"📂 Detected nested run folder, using: {nested}\")\n",
        "    latest_model = nested\n",
        "\n",
        "print(f\"\\n📁 Latest model directory: {latest_model}\")\n",
        "\n",
        "# =========================================================\n",
        "# Load training log (training_log.csv)\n",
        "# =========================================================\n",
        "metrics_path = os.path.join(latest_model, \"training_log.csv\")\n",
        "if not os.path.exists(metrics_path):\n",
        "    raise FileNotFoundError(f\"No training_log.csv found in {latest_model}\")\n",
        "\n",
        "df = pd.read_csv(metrics_path)\n",
        "if \"epoch\" not in df.columns:\n",
        "    raise ValueError(\"training_log.csv missing 'epoch' column; check SLEAP output\")\n",
        "\n",
        "print(f\"\\n✅ Metrics loaded successfully ({len(df)} epochs).\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# =========================================================\n",
        "# Identify best epoch (minimum validation loss)\n",
        "# =========================================================\n",
        "best_idx = df[\"val_loss\"].idxmin()\n",
        "best_row = df.loc[best_idx]\n",
        "best_epoch = int(best_row[\"epoch\"])\n",
        "best_val_loss = best_row[\"val_loss\"]\n",
        "best_train_loss = best_row[\"train_loss\"]\n",
        "loss_ratio = best_val_loss / best_train_loss if best_train_loss != 0 else None\n",
        "\n",
        "print(\"\\n🔍 Best Model Summary\")\n",
        "print(f\"  • Epoch: {best_epoch}\")\n",
        "print(f\"  • Validation Loss: {best_val_loss:.5f}\")\n",
        "print(f\"  • Training Loss:   {best_train_loss:.5f}\")\n",
        "print(f\"  • Val/Train Ratio: {loss_ratio:.3f} (≈1.0 ideal)\\n\")\n",
        "\n",
        "# =========================================================\n",
        "# Load evaluation metrics from .npz files\n",
        "# =========================================================\n",
        "train_npz = os.path.join(latest_model, \"train_0_pred_metrics.npz\")\n",
        "val_npz = os.path.join(latest_model, \"val_0_pred_metrics.npz\")\n",
        "\n",
        "def load_npz_metrics(npz_path, label):\n",
        "    \"\"\"Robustly extract OKS, distances, etc. from SLEAP .npz files.\"\"\"\n",
        "    if not os.path.exists(npz_path):\n",
        "        return {}\n",
        "\n",
        "    data = np.load(npz_path)\n",
        "    keys = list(data.keys())\n",
        "\n",
        "    def safe_get(*names):\n",
        "        for name in names:\n",
        "            if name in data:\n",
        "                val = data[name]\n",
        "                if isinstance(val, np.ndarray):\n",
        "                    val = val[0] if val.size == 1 else np.mean(val)\n",
        "                return float(val)\n",
        "        return np.nan\n",
        "\n",
        "    return {\n",
        "        f\"{label}_OKS_mAP\": safe_get(\"oks_map\", \"OKS_mAP\", \"oks\", \"mean_oks\", \"oks.mean\"),\n",
        "        f\"{label}_avg_dist\": safe_get(\"mean_distance\", \"avg_distance\", \"mean_distances\", \"dist_mean\"),\n",
        "        f\"{label}_p90_dist\": safe_get(\"p90\", \"p90_dist\", \"dist_p90\"),\n",
        "        f\"{label}_p50_dist\": safe_get(\"p50\", \"p50_dist\", \"dist_p50\")\n",
        "    }\n",
        "\n",
        "extra_metrics = {}\n",
        "extra_metrics.update(load_npz_metrics(train_npz, \"train\"))\n",
        "extra_metrics.update(load_npz_metrics(val_npz, \"val\"))\n",
        "\n",
        "if extra_metrics:\n",
        "    print(\"📈 Evaluation metrics (.npz):\")\n",
        "    for k, v in extra_metrics.items():\n",
        "        if not np.isnan(v):\n",
        "            print(f\"  • {k}: {v:.4f}\")\n",
        "else:\n",
        "    print(\"⚠️ No .npz metric files found (train_0_pred_metrics.npz / val_0_pred_metrics.npz).\")\n",
        "\n",
        "# =========================================================\n",
        "# Estimate runtime (if available)\n",
        "# =========================================================\n",
        "runtime_sec = None\n",
        "try:\n",
        "    if \"timestamp\" in df.columns:\n",
        "        runtime_sec = (df[\"timestamp\"].iloc[-1] - df[\"timestamp\"].iloc[0])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# =========================================================\n",
        "# Plot training vs validation losses\n",
        "# =========================================================\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
        "plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "if SAVE_FIGS:\n",
        "    loss_fig_path = os.path.join(latest_model, f\"loss_curve_{datetime.now().strftime('%Y%m%d_%H%M')}.png\")\n",
        "    plt.savefig(loss_fig_path, dpi=300, bbox_inches=\"tight\")\n",
        "    print(f\"📊 Saved loss curve: {loss_fig_path}\")\n",
        "plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# Per-keypoint validation losses\n",
        "# =========================================================\n",
        "keypoint_cols = [c for c in df.columns if any(k in c for k in [\"head\", \"thorax\", \"leg\", \"abdomen\"])]\n",
        "\n",
        "if keypoint_cols:\n",
        "    best_keypoint_losses = df.loc[best_idx, keypoint_cols].sort_values()\n",
        "    print(\"\\n🎯 Per-keypoint validation losses (best epoch):\")\n",
        "    print(best_keypoint_losses.round(6).to_string())\n",
        "\n",
        "    plt.figure(figsize=(9,5))\n",
        "    best_keypoint_losses.plot.bar()\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Per-Keypoint Validation Losses (Epoch {best_epoch})\")\n",
        "    plt.grid(True, axis='y')\n",
        "    if SAVE_FIGS:\n",
        "        kp_fig_path = os.path.join(latest_model, f\"keypoint_losses_{datetime.now().strftime('%Y%m%d_%H%M')}.png\")\n",
        "        plt.savefig(kp_fig_path, dpi=300, bbox_inches=\"tight\")\n",
        "        print(f\"📊 Saved keypoint loss plot: {kp_fig_path}\")\n",
        "    plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# Export summary metrics to CSV\n",
        "# =========================================================\n",
        "summary = {\n",
        "    \"model_dir\": latest_model,\n",
        "    \"best_epoch\": best_epoch,\n",
        "    \"val_loss\": best_val_loss,\n",
        "    \"train_loss\": best_train_loss,\n",
        "    \"val/train_ratio\": loss_ratio,\n",
        "    \"runtime_sec\": runtime_sec,\n",
        "    \"num_epochs\": len(df),\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "}\n",
        "summary.update(extra_metrics)\n",
        "\n",
        "summary_df = pd.DataFrame([summary])\n",
        "summary_csv_path = os.path.join(latest_model, \"summary_metrics.csv\")\n",
        "summary_df.to_csv(summary_csv_path, index=False)\n",
        "\n",
        "print(f\"\\n🧾 Summary metrics saved to: {summary_csv_path}\")\n",
        "print(\"\\n✅ Done! Generated inside model folder:\")\n",
        "print(\"  • loss_curve_*.png → Training curve\")\n",
        "print(\"  • keypoint_losses_*.png → Per-keypoint bar plot\")\n",
        "print(\"  • summary_metrics.csv → Numerical report\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-75_EKoM889R",
        "outputId": "7a805264-7440-4612-a5f4-3b9a7486b8b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📁 Latest model directory: models/drosophila_unet_1_251019_094425\n",
            "\n",
            "✅ Metrics loaded successfully (51 epochs).\n",
            "Columns: ['epoch', 'train_loss', 'val_loss', 'learning_rate', 'train_time', 'val_time', 'head1', 'thorax1', 'abdomen1', 'forelegR1', 'forelegL1', 'midlegR1', 'midlegL1', 'hindlegR1', 'hindlegL1']\n",
            "\n",
            "🔍 Best Model Summary\n",
            "  • Epoch: 19\n",
            "  • Validation Loss: 0.00009\n",
            "  • Training Loss:   0.00004\n",
            "  • Val/Train Ratio: 1.910 (≈1.0 ideal)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for /: 'dict' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py\u001b[0m in \u001b[0;36m_divide_by_count\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dtype'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2117559611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mextra_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mextra_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_npz_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_npz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mextra_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_npz_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_npz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2117559611.py\u001b[0m in \u001b[0;36mload_npz_metrics\u001b[0;34m(npz_path, label)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mOKS.npy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"mOKS.npy\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mOKS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{label}_OKS_mAP\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# 2️⃣ Distance metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n\u001b[1;32m   1063\u001b[0m                  where=where)\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_divide_by_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0misbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py\u001b[0m in \u001b[0;36m_divide_by_count\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# This is questionable, but currently a numpy scalar can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'dict' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "If instead of bottom-up you've chosen the top-down pipeline (with two training configs), you would need to invoke two separate training jobs in sequence:\n",
        "\n",
        "- `!sleap-train centroid.json colab.pkg.slp`\n",
        "- `!sleap-train centered_instance.json colab.pkg.slp`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsKUX661xFK"
      },
      "source": [
        "## Run inference to predict instances\n",
        "\n",
        "Once training finishes, you'll see a new directory (or two new directories for top-down training pipeline) containing all the model files SLEAP needs to use for inference.\n",
        "\n",
        "Here we'll use the created model files to run inference in two modes:\n",
        "\n",
        "- predicting instances in suggested frames from the exported .slp file\n",
        "\n",
        "- predicting and tracking instances in uploaded video\n",
        "\n",
        "You can also download the trained models for running inference from the SLEAP GUI on your computer (or anywhere else).\n",
        "\n",
        "### Predicting instances in suggested frames\n",
        "This mode of predicting instances is useful for accelerating the manual labeling work; it allows you to get early predictions on suggested frames and merge them back into the project for faster labeling.\n",
        "\n",
        "Here we assume you've trained a bottom-up model and that the model files were written in directory named `colab_demo.bottomup`; later in this notebook we'll also show how to run inference with the pair of top-down models instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPXxZjTjhZGn"
      },
      "outputs": [],
      "source": [
        "!sleap-track \\\n",
        "    -m colab_demo.bottomup \\\n",
        "    --only-suggested-frames \\\n",
        "    -o colab.predicted_suggestions.slp \\\n",
        "    colab.pkg.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdOd0T9GhZGo"
      },
      "source": [
        "Now, you can download the generated `colab.predicted_suggestions.slp` file and merge it into your labeling project (**File -> Merge into Project...** from the GUI) to get new predictions for your suggested frames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6xTnm2YhZGp"
      },
      "source": [
        "### Predicting and tracking instances in uploaded video\n",
        "Let's first upload the video we want to run inference on and name it `colab_demo.mp4`. (If your video is not named `colab_demo.mp4`, adjust the names below accordingly.)\n",
        "\n",
        "For this demo we'll just get predictions for the first 200 frames (or you can adjust the --frames parameter below or remove it to run on the whole video)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLtjtq9E1Znr"
      },
      "outputs": [],
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m colab_demo.bottomup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzObCUToEqwA"
      },
      "source": [
        "When inference is finished, it will save the predictions in a file which can be opened in the GUI as a SLEAP project file. The file will be in the same directory as the video and the filename will be `{video filename}.predictions.slp`.\n",
        "\n",
        "Let's inspect the predictions file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPfmNMSt-vS7"
      },
      "outputs": [],
      "source": [
        "!sleap-inspect colab_demo.mp4.predictions.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJ2kNBK-w6k"
      },
      "source": [
        "You can copy this file from your Google Drive to a local drive and open it in the SLEAP GUI app (or open it directly if you have your Google Drive mounted on your local machine). If the video is in the same directory as the predictions file, SLEAP will automatically find it; otherwise, you'll be prompted to locate the video (since the path to the video on your local machine will be different than the path to the video on Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-NoJOFvYHM"
      },
      "source": [
        "### Inference with top-down models\n",
        "\n",
        "If you trained the pair of models needed for top-down inference, you can call `sleap-track` with `-m path/to/model` for each model, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKnMc1qvim7"
      },
      "outputs": [],
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m colab_demo.centered_instance \\\n",
        "    -m colab_demo.centroid"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training_and_inference_using_Google_Drive.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}